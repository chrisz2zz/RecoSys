#### DeepWalk

DeepWalk的主要思想是在**由物品组成的图结构上进行随机游走，产生大量物品序列，然后将这些物品序列作为训练样本输入word2vec进行训练，得到物品的embedding**

##### 算法流程

![](https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/30-1.jpeg)

- 图a展示了原始的用户行为序列
- 图b基于这些用户行为序列构建了物品相关图，其中，物品A, B之间的边产生的原因就是因为用户U1先后购买了物品A和物品B，所以产生了一条由A到B的有向边。如果**后续产生了多条相同的有向边，则有向边的权重被加强**。在将所有用户行为序列都转换成物品相关图中的边之后，全局的物品相关图就建立起来了
- **图c采用随机游走的方式随机选择起始点，重新产生物品序列**
- 图d最终**将这些物品序列输入word2vec模型，生成最终的物品Embedding向量**

在上述DeepWalk的算法流程中，**核心是第三步**，其中**唯一需要形式化定义的是随机游走的跳转概率，也就是到达节点vi后，下一步遍历vi的临接点vj的概率**。如果物品的相关图是有向有权图，那么从节点vi跳转到节点vj的概率定义如下：
$$
P\left(v_{j} \mid v_{i}\right)=\left\{\begin{array}{ll}\frac{\mathrm{M}_{i j}}{\sum_{j \in N_{+}\left(v_{i}\right)} \mathrm{M}_{i j}}, & v_{j} \in N_{+}\left(v_{i}\right) \\ 0, & e_{i j} \notin \mathcal{E}\end{array}\right.
$$
其中**N+(vi)是节点vi所有的出边集合，Mij是节点vi到节点vj边的权重**

**如果物品相关图是无向无权重图，那么跳转概率将是上面公式的一个特例，即权重Mij将为常数1，且N+(vi)应是节点vi所有“边”的集合，而不是所有“出边”的集合**

#### Node2vec

Node2vec 是在DeepWalk的基础上更进一步，**通过调整随机游走权重的方法**使graph embedding的结果在网络的**同质性（homophily）**和**结构性（structural equivalence）**中进行权衡

<u>**“同质性”**指的是**距离相近节点的embedding应该尽量近似**，如**图4，节点u与其相连的节点s1、s2、s3、s4**的embedding表达应该是接近的，这就是“同质性“的体现</u>

<u>**“结构性”**指的是**结构上相似的节点的embedding应该尽量接近**，**图4中节点u和节点s6**都是各自局域网络的中心节点，结构上相似，其embedding的表达也应该近似，这是“结构性”的体现</u>

<img src="https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/30-2.jpg" style="zoom:33%;" />

Node2vec在具体的实现上，是通过调整模型参数，使随机游走更倾向于广度优先搜索（BFS），或者深度优先搜索（DFS），从而在embedding结果中更好的体现“结构性”或者“同质性”

##### BFS与结构性 

对于广度优先搜索（BFS）来说，其搜索往往是在当前节点（这里以节点u为例）的邻域进行的，特别是在node2vec中，由于存在所谓的“返回概率”，所以即使从u搜索到了s1，也有很大概率从s1再返回u，**所以BFS产生的序列往往是在u附近的节点间进行来回的震荡**，这就**相当于对u周围的网络结构**进行了一次**微观扫描（microscope view）**

那么微观扫描当然更容易得到**微观结构**的观察，所以**BFS就更容易使embedding结果更多反应网络的“结构性”**。这里对“结构性”的理解，正如上面所说的一样，这里的**“结构”更多的指的是微观结构，而不是大范围内，甚至整个网络范围内的宏观结构，而是一阶、二阶范围内的微观结构。**

##### DFS与同质性

**“同质性”不是指一阶、二阶这类非常局限的同质性，而是在相对较广范围内的，能够发现一个社区、一个群、一个聚集类别的“同质性”。**要发现这类同质性，当然需要使用DFS进行更广范围内的探索。如果仅用BFS在微观范围内探索，如何发现一个社区的边界在哪里呢？

所以，**DFS相当于对网络结构进行了一次宏观扫描**（macroscope view），**只有在宏观的视角，才能发现大的集团、社区的聚集性，和集团内部节点的“同质性”。**

##### 跳转算法

在node2vec算法中，是怎样控制BFS和DFS的倾向性的呢？主要是通过节点间的跳转概率。图5显示了node2vec算法**从节点t跳转到节点v后**，下一步从**节点v跳转到周围各点的跳转概率**

<img src="https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/30-3.jpg" style="zoom:33%;" />

形式化来讲，**从节点v跳转到下一个节点x的概率为**：
$$
\pi_{\mathrm{vx}}=\alpha_{p q}(t, x) \cdot \omega_{v x}
$$
其中，$\omega_{v x}$ 是**是边vx的权重**，$\alpha_{p q}(t, x)$ 的定义如下：
$$
\alpha_{p q}(t, x)=\left\{\begin{array}{ll}\frac{1}{p} & \text { if } d_{t x}=0 \\ 1 & \text { if } d_{t x}=1 \\ \frac{1}{q} & \text { if } d_{t x}=2\end{array}\right.
$$
其中，**dtx指的是节点t到节点x的距离，参数p和q共同控制着随机游走的倾向性**。

参数p被称为返回参数（return parameter），**p越小，随机游走回节点t的可能性越大，node2vec就更注重表达网络的结构性**

参数q被称为进出参数（in-out parameter），**q越小，则随机游走到远方节点的可能性越大，node2vec更注重表达网络的同质性，反之，当前节点更可能在附近节点游走**

<img src="https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/30-4.jpg" style="zoom:33%;" />

论文中最后通过实验的方式验证了DFS和BFS对于“同质性”和“结构性”的挖掘结果。颜色接近的节点代表其embedding的相似性更强。

图2上图是node2vec更倾向于**DFS的结果，可以看到各聚类的内部节点相似，这是网络“同质性”的体现**；而图2**下图是BFS的结果，结构类似节点的embedding更为相似，这是“结构性”的体现**。

node2vec所体现的网络的同质性和结构性在推荐系统中也是可以被很直观的解释的。**同质性相同的物品很可能是同品类、同属性、或者经常被一同购买的物品**，而**结构性相同的物品则是各品类的爆款、各品类的最佳凑单商品等拥有类似趋势或者结构性属性的物品**。毫无疑问，二者在推荐系统中都是非常重要的特征表达。由于node2vec的这种灵活性，以及发掘不同特征的能力，甚至可以把不同node2vec生成的embedding融合共同输入后续深度学习网络，以保留物品的不同特征信息。

**结构性关注的特定节点**在系统中的相对位置（居于中心还是边缘），而不关心节点本身的特有的属性。**类似每个品类的热门商品，热销商品，凑单商品等容易有这样的特点**。

**同质性相反，更多关注内容之间本身的相似性，所以同品类，同店铺，同价格区间等内容更容易表现同质性**

