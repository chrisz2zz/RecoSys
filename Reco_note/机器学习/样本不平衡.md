#### 样本不平衡  =  类别不平衡

所谓的类别不平衡问题指的是**数据集中各个类别的样本数量极不均衡**。以二分类问题为例，假设正类的样本数量远大于负类的样本数量，通常情况下把样本类别比例超过4:1（也有说3:1）的数据就可以称为不平衡数据。

样本不平衡实际上是一种非常常见的现象。比如：在欺诈交易检测，欺诈交易的订单应该是占总交易数量极少部分；工厂中产品质量检测问题，合格产品的数量应该是远大于不合格产品的；信用卡的征信问题中往往就是正样本居多。

**为什么很多分类模型在训练数据不均衡时会出现问题？**本质原因是**模型在训练时优化的目标函数和人们在测试时使用的评价标准不一致**。

- 这种“不一致”**可能是由于训练数据的样本分布与测试时期望的样本分布不一致**，例如，在训练时优化的是整个训练集（正负样本比例可能是1∶99）的正确率，而测试时可能想要模型在正样本和负样本上的平均正确率尽可能大（实际上是期望正负样本比例为 1∶1）；
- 也可能是**由于训练阶段不同类别的权重（重要性）与测试阶段不一致**， 例如训练时认为所有样本的贡献是相等的，而测试时假阳性样本（False Positive） 和伪阴性样本（False Negative）有着不同的代价。

#### 问题

类别不平衡会**使得分类模型存在很严重的偏向性，但是从一些常用的指标上又无法看出来**。

如果直接采用不均衡的样本集来进行训练学习，会存在一些问题。例如，如果正负样本比例达到1∶99，则 分类器简单地将所有样本都判为负样本就能达到99%的正确率，显然这并不是我们想要的，我们想让分类器在正样本和负样本上都有足够的准确率和召回率

#### 数据角度出发的解决方案

**扩大数据集**

- 当遇到类别不均衡问题时，首先应该想到，**是否可能再增加数据（一定要有小类样本数据），更多的数据往往战胜更好的算法**。因为机器学习是使用现有的数据的分布进行估计，因此**更多的数据往往能够得到更多的分布信息**，以及更好分布估计。即使再增加小类样本数据时，又增加了大类样本数据，**也可以使用放弃一部分大类数据（即对大类数据进行欠采样）来解决**

**数据重采样**

- **最简单的处理不均衡样本集的方法是随机采样**。采样主要分为两种：**过采样和欠采样**
  - **对小类的数据样本进行采样来增加小类的数据样本个数**，即过采样（over-sampling ，采样的个数大于该类样本的个数）
  - **对大类的数据样本进行采样来减少该类数据样本的个数**，即欠采样（under-sampling，采样的次数少于该类样本的个素）
- 考虑对大类下的样本（超过1万、十万甚至更多）进行欠采样，即删除部分样本；
- 考虑对小类下的样本（不足1为甚至更少）进行过采样，即添加部分样本的副本；
- 考虑尝试随机采样与非随机采样两种采样方法；
- 考虑对各类别尝试不同的采样比例，比一定是1:1，有时候1:1反而不好，因为与现实情况相差甚远；
- 考虑同时使用过采样与欠采样


在实际应用中，具体的采样操作可能并不总是如上述几个算法一样，但基本思路很多时候还是一致的。

- 例如，**基于聚类的采样方法，利用数据的类簇信息来 指导过采样/欠采样操作**；

- 经常用到的数据扩充方法也是一种过采样，对少数类样本进行一些噪声扰动或变换（如图像数据集中对图片进行裁剪、翻转、旋转、加 光照等）以构造出新的样本；
- 而Hard Negative Mining则是一种欠采样，把比较难的样本抽出来用于迭代分类器。

**人工产生数据样本**

- 一种简单的人工样本数据产生的方法便是，**对该类下的所有样本每个属性特征的取值空间中随机选取一个组成新的样本，即属性值随机采样**。你可以使用基于经验对属性值进行随机采样而构造新的人工样本，或者使用类似朴素贝叶斯方法假设各属性之间互相独立进行采样，这样便可得到更多的数据，但是无法保证属性之前的线性关系（如果本身是存在的）。
- 有一个系统的构造人工数据样本的方法SMOTE(Synthetic Minority Over-sampling Technique)。SMOTE是一种过采样算法，它构造新的小类样本而不是产生小类中已有的样本的副本，即**该算法构造的数据是新样本，原数据集中不存在的。该基于距离度量选择小类别下两个或者更多的相似样本，然后选择其中一个样本，并随机选择一定数量的邻居样本对选择的那个样本的一个属性增加噪声，每次处理一个属性**。这样就构造了更多的新生数据。具体可以参见原始论文

#### 算法角度解决方案

**尝试不同的分类算法**

- 强烈建议不要对待每一个分类都使用自己喜欢而熟悉的分类算法。**应该使用不同的算法对其进行比较**，因为不同的算法使用于不同的任务与数据。
- **决策树往往在类别不均衡数据上表现不错**。它**使用基于类变量的划分规则去创建分类树，因此可以强制地将不同类别的样本分开**。目前流行的决策树算法有：C4.5、C5.0、CART和Random Forest等。

**对小类错分进行加权惩罚**

- **对分类器的小类样本数据增加权值，降低大类样本的权值（这种方法其实是产生了新的数据分布，即产生了新的数据集，译者注），从而使得分类器将重点集中在小类样本身上。**一个具体做法就是，在训练分类器时，若分类器将小类样本分错时额外增加分类器一个小类样本分错代价，这个额外的代价可以使得分类器更加“关心”小类样本。如penalized-SVM和penalized-LDA算法。
- 对小样本进行过采样（例如含L倍的重复数据），其实在计算小样本错分cost functions时会累加L倍的惩罚分数。
- 在样本不均衡时，也可以**通过改变模型训练时的目标函数（如代价敏感学习中不同类别有不同的权重）来矫正这种不平衡性**

**从重构分类器的角度出发**

- 仔细对你的问题进行分析与挖掘，是否可以将你的问题划分成多个更小的问题，而这些小问题更容易解决

  - 将你的大类压缩成小类
  - 使用One Class分类器（将小类作为异常点）
  - 使用集成方式，训练多个分类器，然后联合这些分类器进行分类
  - 将二分类问题改成多分类问题

