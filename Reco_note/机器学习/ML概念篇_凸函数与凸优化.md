### 1. 前言

- 笔者最近在学习机器学习的优化问题时，凸集、凸函数、凸优化等问题经常很让人头大，而这些概念也是ML的基础概念，是各种证明问题的前提条件，笔者打算从这篇开始记录所学ML概念。

### 2. 凸集

- **定义**
  - 集合C内任意两点间的线段也均在集合C内，则称集合C为凸集。
- 数学定义：
- <img src="https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/13-1.jpg" style="zoom:50%;" />
- 上面凸集定义中便用到了线段的向量表示，含义是如果点x1和点x2在集合C内，则线段x1x2上所有点都在集合c内，凸集的交集仍是凸集，下面展示几个凸集示例：

<img src="https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/13-2.jpg" style="zoom:33%;" />

### 3. 凸函数

- **定义**
  - 定义域C是一个凸集，任取$x_1,x_2 \in C$，有$f(a_1x_1+a_2x_2) <= a_1f(x_1)+a_2f(x_2)，\sum a_i=1，a_i >0$，则定义f(x)为定义在凸集C上的凸函数。

- **几何解释**

  - 凸函数公式描述如上，接下图：设A1、A2是凸函数曲线上的两个点，他们对应的横坐标$x_1<x_2$，且$x \in (x_1, x_2)$，则存在 $α_1， α_2>0$且 $α_1+ α_2=1$，使得$x= α_1x_1+ α_2x_2$，过点x做x轴的垂线交函数于A，交直线A1A2于B点，则上式左端即为A的纵坐标，右端即为B的纵坐标：

  $$
  y_A = f(a_1x_1+a_2x_2) \\ y_B = a_1f(x_1)+a_2f(x_2)
  $$

  - 因此，凸函数的几何含义是：函数任意两点A1和A2之间的部分位于弦A1A2的下方，或曲线任一点切线上方，不严谨一个说法：割线始终位于两点间函数曲线的上方。

![](https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/13-3.png)

- **凸优化问题的局部极小值是全局最小值证明**
- 在机器学习任务中我们只需将非凸问题转化为凸优化问题，便可直接求出问题的全局极值，下面给出证明：

![](https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/13-4.jpg)

- 我们观察下面两幅图，形象感受一下为什么凸优化问题的局部最优解是全局最优解：

  - 从下图可以看出当函数不是凸函数时，当对非凸函数f(x)进行最优化时，便可能得到局部最优解，无法获得全局最优解

  ![](https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/13-5.jpeg)

  - 从下图可以看出当目标函数可行域是非凸时，则此时对函数进行优化时也可能错过全局最优解

  ![](https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/13-6.jpeg)

### 4. 凸优化

- **定义**

  - 一个凸优化问题可描述为：

  $$
  \begin{array}{c}{f(x) \quad \text { s.t. } x \in C} \\ {\text { s.t. } g_{i}(x)<=0 \quad h_{i}(x)=0}\end{array}
  $$

- **凸优化的性质**
  - 目的是求解目标函数的最小值
  - 目标函数f(x)和不等式约束函数g(x)都是凸函数，定义域是凸集
  - 若存在等式约束函数，则等式约束函数h(x)为仿射函数；仿射函数指的是最高次数为1的多项式函数，一般形式为f(x)= Ax + b，A是m*k矩阵，x是一个k向量，b是一个m向量
  -  凸优化问题有一个良好的性质即：局部最优解便是全局最优解