#### 召回负样本和精排有什么区别

召回/粗排/精排：**不同阶段训练样本也不同**。对于CTR目标最通用的做法：

- **精排：正样本-真实点击； 负样本-真实未点击**
- 粗排：根据模型不同有不同的方法，比如使用蒸馏的话和精排样本一致，非蒸馏也可以用级联样本等，不作此文重点。
- **召回**：正样本-真实点击； **负样本-真实未点击 + 负采样**

可以看到**召回是要做采样的**，其原因是：**离线训练数据要和线上分布尽可能一致，虽然曝光未点击肯定是负样本，但是还有很多视频未曝光，同时因为推荐系统bias的存在可能某些样本你永远学不到，负采样的目的就是尽量符合线上真实分布，要让模型“见见世面“**

#### 启发式负采样

**1. 随机负采样（Random Negative Sampling, RNS）**

RNS是最基本的负采样算法，它的思想就是平等地对待采样池内的每一个商品，按相等的概率进行采样。RNS的算法逻辑非常简单，在效率上有着很大的优势，同时也避免在采样过程中引入新的偏差，是一个被广泛使用的采样算法

整体来说，随机负采样能够解决本文最开始提到的“开开眼”，**但是由于高热/人群偏差等，纯随机还是不太好，有较大的bias，且负例不够难，只能学到粗粒度上差异，对小众不友好**

**2. 基于流行度的负采样（Popularity-biased Negative Sampling, PNS）**

PNS也是一个启发式的负采样算法，它的思想是**以商品流行度作为采样权重对采样池内的商品进行带权采样，流行度越高的商品越容易被采到**。这里的流行度有很多种定义方式，一种常见的定义方式该商品的历史交互次数，即商品被消费次数越多，其流行度就越高。这种算法相比于RNS，就是将均匀分布替换成一个基于流行度的采样分布，只需要在采样前计算出每个商品的流行度作为采样分布，然后就按照这个分布进行采样即可，在开销上没有增加特别多。

相比于RNS, **按照流行度采样的目的是为了提高所采负例的信息量，提高采样质量。例如一个非常流行的商品，却出现在某个用户的未交互商品集中，那么这个商品就很大概率是用户不喜欢的商品，那么通过这个负例就可以很好的学习到用户的喜好；相反，一个大家都不喜欢的商品，将它作为负例进行学习，其实能够带给模型的信息量就很少了，很难学习到该用户的个性化特征**。

但也有文献指出 [3]，PNS也有一定的局限性。首先，因为PNS的采样分布是提前计算好的，在模型训练过程中，采样分布不会变化。因此那些在训练初期能够提高更高信息量的负例，在经过多次训练后，其带来信息量可能会有所下降。其次，流行度的引入也可能会引入新的偏差，因为流行度的计算是全局的，而在用户中，不同用户类别之间的兴趣可能是有差异的，如果所给数据中的用户类别分布不均匀，就可能导致流行度的定义出现偏差

理想情况下，**比较强的正/负例让模型学到正向特殊性，菜一些的正/负例让模型见见世面**，菜的容易搞，强的怎么弄呢？可以有一些易实现的采样思路：

- **当热门物料做正样本时，要降采样，防止所有人的召回结果都集中于少数热门物料**
- **当热门物料做负样本时，要适当过采样，增加负样本难度**

**3.  业务逻辑选取负样本**

Airbnb在《Real-time Personalization using Embeddings for Search Ranking at Airbnb》一文中的做法。

- **增加与正样本同城的房间作为负样本，增强了正负样本在地域上的相似性，加大了模型的学习难度**
- 增**加“被房主拒绝”作为负样本，增强了正负样本在“匹配用户兴趣爱好”上的相似性，加大了模型的学习难度**

#### 召回及粗排的负例选择问题

**训练精排模型的时候（假设是优化点击目标），一般会用“用户点击”实例做为正例，“曝光未点击”实例做为负例，来训练模型**，基本大家都是这么干的。现在，模型召回以及粗排，也需要训练模型，意思是说，也需要定义正例和负例。一般正例，也都是用“用户点击”实例做为正例，但是怎么选择负例，这里面有不少学问

<img src="https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/28-5.png" style="zoom:33%;" />

先来看下不同阶段模型面对的输入数据情况

- 对于召回模型来说，它面临的输入数据，是所有物料库里的物品；
- 对于粗排模型来说，它面对的输入数据，是各路召回的结果；
- 对于精排模型来说，它面临的输入是粗排模型的输出结果。

**如果我们仍然用“曝光未点击”实例做为召回和粗排的负例训练数据，你会发现这个训练集合，只是全局物料库的一小部分，它的分布和全局物料库以及各路召回结果数据，这两个召回和粗排模型面临的实际输入数据，分布差异比较大，所以根据这种负例训练召回和粗排模型，效果如何就带有疑问，我们一般把这个现象称为“Sample Selection Bias”问题。**

为了解决“Sample Selection Bias”问题，我们在召回或者粗排模型训练的时候，应该调整下负例的选择策略，使得它尽量能够和模型输入的数据分布保持一致。这里归纳下可能的做法

- **曝光未点击数据**

这就是上面说的导致Sample Selection Bias问题的原因。我们的经验是，这个数据还是需要的，**只是要和其它类型的负例选择方法，按照一定比例进行混合，来缓解Sample Selection Bias问题**。当然，有些结论貌似是不用这个数据，所以用还是不用，可能跟应用场景有关

- **全局随机选择负例**

在原始的全局物料库里，随机抽取做为召回或者粗排的负例。这也是一种做法，Youtube DNN双塔模型就是这么做的。**从道理上讲，这个肯定是完全符合输入数据的分布一致性的，但是，一般这么选择的负例，因为和正例差异太大，导致模型太好区分正例和负例，所以模型能学到多少知识是成问题的**

- **Batch内随机选择负例**

**就是说只包含正例，训练的时候，在Batch内，选择除了正例之外的其它Item，做为负例。这个本质上是：给定用户，在所有其它用户的正例里进行随机选择，构造负例**。它在一定程度上，也可以解决Sample Selection Bias问题。比如Google的双塔召回模型，就是用的这种负例方法。

- **曝光数据随机选择负例**

**在给所有用户曝光的数据里，随机选择做为负例**。这个我们测试过，在某些场景下是有效的。

- **基于Popularity随机选择负例**

**全局随机选择，但是越是流行的Item，越大概率会被选择作为负例**。目前不少研究证明了，负例采取Popularity-based方法，对于效果有明显的正面影响。**它隐含的假设是：如果一个例子越流行，那么它没有被用户点过看过，说明更大概率，对当前的用户来说，它是一个真实的负例。同时，这种方法还会打压流行Item，增加模型个性化程度**。

- **基于Hard选择负例**

**选择那些比较难的例子，做为负例。因为难区分的例子，很明显给模型带来的loss和信息含量比价多，所以从道理上讲是很合理的**。但是怎样算是难的例子，可能有不同的做法，有些还跟应用有关。比如Airbnb，还有不少工作，都是在想办法筛选Hard负例上。

