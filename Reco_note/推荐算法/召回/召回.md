#### 主流的召回方法

**传统召回**

- content-based
  - item&用户画像
- 协同过滤
  - memory-based
    - Item-cf
    - User-cf
  - Model-based
    - FM 加入side information

**Embedding 表示学习**

- YouTube DNN 架构

  - [YouTube单塔结构](/Users/yearing1017/学习/笔记/推荐算法/YouTube 推荐系统架构.md)
  - user_embedding和item_embedding的生成问题
    - **用户向量是神经网络最后的输出  1xd 的Embedding 向量;**  
    - **假设有n类，用户向量经过softmax 会得到 1x n 的概率；而中间 会 经过一个 dxn 的矩阵，这个矩阵就是item_embdding**
      - 最后的输出层是 softmax，**而 softmax 层的参数本质上就是一个 m x n 维的矩阵，其中 m 指的是最后一层红色的 ReLU 层的维度 m，n 指的是分类的总数，即 YouTube 所有视频的总数 n。因此，视频 Embedding 就是这个 m x n 维矩阵的各列向量**

- DeepMF

- **双塔DSSM**

  - [DSSM及双塔](/Users/yearing1017/学习/笔记/推荐算法/DSSM 双塔.md)

- **item2vec**

  - word2vec的思想；但word2vec不能改变句子中词的顺序，但item2vec中item的顺序，进行shuffle反而是有益的
  - 与word2vec不同的是，**可以对一个session内的用户的行为序列进行shuffle；例如30分钟内的用户行为序列**

- **airbnb embedding**

  - 将最后一个预定的房源 无论在不在窗口内 都当做正样本
  - 除全局随机负采样之外；加入一个按城市进行负采样 
  - 冷启动策略  新房源的emdedding 通过 寻找 位置、价格、房源类型最类似的 找到 地理位置中 最近的三个 房源的 embedding 加起来平均，当做新房源的embedding

- **Random Walk methods**

  - [Deep walk](/Users/yearing1017/学习/笔记/推荐算法/DeepWalk与Node2vec.md)

    - 随机游走的概率
      - 有向图：边的权重/一个点的出度
      - 无向图：1/这个点的边的集合总数

  - **node2vec**

    -  Node2vec 相比于 Deep Walk，增加了随机游走过程中跳转概率的倾向性。
      - 如果倾向于宽度优先搜索，则 Embedding 结果更加体现“结构性”。
      - 如果倾向于深度优先搜索，则更加体现“同质性”
    - 随机游走的方式与deepwalk不同
      - p越小，1/p越大；随机游走回节点t的可能性越大，node2vec就更注重表达网络的**结构性**
      - q越小，1/q越大；则随机游走到远方节点的可能性越大，node2vec更注重表达网络的**同质性**

  - **Base Graph Embedding（BGE）**

    - 该方案是 DeepWalk 算法的实践，与 DeepWalk 不同的是：

      （1）**通过 user 的行为序列构建网络结构，并将网络定义为有向有权图**。

      （2）**其中：根据行为的时间间隔，将一个 user 的行为序列分割为多个session**

  - **Graph Embedding with Side Information（GES）**

    - 该方案增加 item 的额外信息（例如category, brand, price等）丰富 item 表征力度。根据 **EGES**的算法框架可知：

      （1）**item 和 side information（例如category, brand, price等） 的 Embedding 是通过 word2vec 算法一起训练得到的。**如果分开训练，得到的item_embedding和category_embedding（brand_embedding，price_embedding）不在一个向量空间中，做运算无意义。

      > 即：通过 DeepWalk 方案得到 item 的游走序列，同时得到对应的category（brand, price）序列。然后将所有序列数据放到word2vec模型中进行训练。

      （2）针对每个 item，将得到：item_embedding，category_embedding，brand_embedding，price_embedding 等 embedding 信息。**将这些 embedding 信息求均值来表示该 item**

  - **Enhanced Graph Embedding with Side Information（EGES）**

    - 基本思想：**在DeepWalk生成的Graph Embedding 基础上引入补充信息（side-information）**
    - 如果单纯使用用户行为生成的物品相关图，固然可以生成物品的embedding，但是如果遇到新加入的物品，或者没有过多互动信息的长尾物品，推荐系统将出现严重的冷启动问题。**为了使“冷启动”的商品获得“合理”的初始Embedding，阿里团队通过引入了更多补充信息来丰富Embedding信息的来源，从而使没有历史行为记录的商品获得Embedding**
    - **组合表示 item_embedding 时，对 item 和 side information（例如category, brand, price等）的embedding施加不同的权重。该权重值通过模型训练得到**
    - 该方案应用**改进的word2vec算法（Weighted Skip-Gram）**确定模型的参数

- Factorization methods
  - LINE
    - **一阶相似度**：两个节点存在直连边，权重就是边的权重；若不直接相连，则权重就是0；
      - 利用经验分布 和 预测两个向量的相似程度分布，通过KL散度，优化交叉熵来训练
    - **二阶相似度**：两个节点不存在直连边，但是他们有很多相同的邻居顶点(1,2,3,4)，这也可以表明这两个是相似的，而2阶相似度就是用来描述这种关系
  - SDNE

- GNN & GCN methods
  - GraphSAGE
  
- Mind（多embedding建模）

- DeepFM 多路召回与模型召回

- SDM 长短兴趣建模