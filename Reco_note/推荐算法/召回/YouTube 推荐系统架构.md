#### 前言

- 本文记录了《深度学习推荐系统实战》**第28讲YouTube推荐系统**的要点
- 课程地址：[深度学习推荐系统实战](https://time.geekbang.org/column/intro/349)

#### YouTube 推荐系统架构

- YouTube 平台中几乎所有的视频都来自 UGC（User Generated Content，用户原创内容），这样的内容产生模式有两个特点：
  - 一是其商业模式不同于 Netflix，以及国内的腾讯视频、爱奇艺这样的流媒体，这些流媒体的大部分内容都是采购或自制的电影、剧集等头部内容，而 YouTube 的内容都是用户上传的自制视频，种类风格繁多，头部效应没那么明显；
  - 二是由于 YouTube 的视频基数巨大，用户难以发现喜欢的内容。

- YouTube 的深度学习推荐系统架构长什么样

<img src="https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/29-5.png" style="zoom:33%;" />

- 为了对海量的视频进行快速、准确的排序，YouTube 也采用了**经典的召回层 + 排序层**的推荐系统架构。

- 推荐过程可以分成二级。**第一级是用候选集生成模型**（Candidate Generation Model）完成候选视频的快速筛选，在这一步，候选视频集合由百万降低到几百量级，这就相当于经典推荐系统架构中的召回层。**第二级是用排序模型（Ranking Model）完成几百个候选视频的精排**，这相当于经典推荐系统架构中的排序层。

#### 候选集生成模型

- 用于视频召回的候选集生成模型的模型架构如下图所示：

<img src="https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/29-6.png" style="zoom:33%;" />

- **最底层是它的输入层**，输入的特征包括用户历史观看视频的 Embedding 向量，以及搜索词的 Embedding 向量。对于这些 Embedding 特征，YouTube 是利用用户的观看序列和搜索序列，采用了类似 Item2vec 的预训练方式生成的。

- 除了视频和搜索词 Embedding 向量，特征向量中还包括用户的地理位置 Embedding、年龄、性别等特征。这里我们需要注意的是，对于样本年龄这个特征，YouTube 不仅使用了原始特征值，还把经过平方处理的特征值也作为一个新的特征输入模型。这个操作其实是为了挖掘特征非线性的特性，当然，这种对连续型特征的处理方式不仅限于平方，其他诸如开方、Log、指数等操作都可以用于挖掘特征的非线性特性。具体使用哪个，需要我们根据实际的效果而定。

- 确定好了特征，这些特征会在 concat 层中连接起来，输入到上层的 ReLU 神经网络进行训练。三层 ReLU 神经网络过后，YouTube 又使用了 softmax 函数作为输出层。值得一提的是，**这里的输出层不是要预测用户会不会点击这个视频，而是要预测用户会点击哪个视频**，这就跟我们之前实现过的深度推荐模型不一样了。

- 比如说，Y**ouTube 上有 100 万个视频，因为输出层要预测用户会点击哪个视频，所以这里的 sofmax 就有 100 万个输出**。因此，**这个候选集生成模型的最终输出，就是一个在所有候选视频上的概率分布。**

#### 线上服务

- 为什么候选集生成模型要用“视频 ID”这个标签，来代替“用户会不会点击视频”这个标签作为预测目标。事实上，这跟候选集生成模型独特的线上服务方式紧密相关。

<img src="https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/29-7.png" style="zoom:33%;" />

- **用户向量是神经网络最后的输出  1xd 的Embedding 向量;**  
- **假设有n类，用户向量经过softmax 会得到 1x n 的概率；而中间 会 经过一个 dxn 的矩阵，这个矩阵就是item_embdding**
  - 最后的输出层是 softmax，**而 softmax 层的参数本质上就是一个 m x n 维的矩阵，其中 m 指的是最后一层红色的 ReLU 层的维度 m，n 指的是分类的总数，即 YouTube 所有视频的总数 n。因此，视频 Embedding 就是这个 m x n 维矩阵的各列向量**
- 架构图左上角的模型服务（Serving）方法与模型训练方法完全不同。**在候选集生成模型的线上服务过程中，YouTube 并没有直接采用训练时的模型进行预测，而是采用了一种最近邻搜索的方法。**
- 具体来说，**在模型服务过程中，网络结构比较复杂，如果我们对每次推荐请求都端到端地运行一遍模型，处理一遍候选集，那模型的参数数量就会巨大，整个推断过程的开销也会非常大。 因此，在通过“候选集生成模型”得到用户和视频的 Embedding 后，我们再通过 Embedding 最近邻搜索的方法，就可以提高模型服务的效率了。**
- 这样一来，我们甚至**不用把模型推断的逻辑搬上服务器，只需要将用户 Embedding 和视频 Embedding 存到特征数据库就行了。再加上可以使用局部敏感哈希这类快速 Embedding 查找方法，这对于百万量级规模的候选集生成过程的效率提升是巨大的**。

#### 向量化检索工具 ANN

- Faiss 10-20ms
- kd_tree 这种大数据 不适合  太慢

#### 采样

- 召回训练模型时  **使用全局的未点击 负采样**
  - 一般大部分都是 **在曝光未点击里 负采样**

- 总结：排序模型  适合在曝光未点击里负采样；召回模型  **适合使用全局的未点击 负采样**  

