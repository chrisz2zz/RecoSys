### 前言

- 本文为传统推荐模型的发展线路及特点总结，包括：**协同过滤、矩阵分解、逻辑回归、FM、FFM、GBDT+LR**
- 本文参考：《深度学习推荐系统--王喆》

### 1. 传统模型的演化

- 如下图所示，可以清晰看出传统的推荐系统模型的演化过程

![](https://blog-1258986886.cos.ap-beijing.myqcloud.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/6-2.jpg)

- 传统推荐模型的发展主要经历了四个阶段：
  - **协同过滤CF算法阶段**：**只需用户物品共现矩阵就可以构建推荐系统**，根据相似度取值对象可分为itemCF和userCF两类，优势是简单易实现。CF的问题是泛化能力弱，无法应对稀疏矩阵，而矩阵分解作为协同过滤的进化版，克服了CF的缺点。
  - **逻辑回归LR阶段**：**综合利用用户、物品、上下文等多种不同的特征，假设用户是否点击广告服从伯努利分布，将推荐问题转化为点击率预估(CTR)问题，预测正样本概率对物品进行排序**。其数学形式是各个特征的加权和经过sigmoid函数，得到用户点击物品的概率。LR的优势是可解释性强、易于并行化、模型简单、训练开销小。其局限性在于表达能力不强，需要大量具有业务背景知识的人工特征筛选与交叉。
  - **因子分解机FM阶段**：**为每个特征学习一个隐向量，在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重**。虽然FM相比POLY2的完全交叉+单一权重记忆能力略弱，但解决了特征交叉过程中交叉特征对应的数据过于稀疏无法充分学习权重的问题。**FFM引入特征域进一步增强了模型的表达能力，做特征交叉时，每个特征选择与对方域对应的隐向量的内积作为交叉特征的权重**，但FFM的计算复杂度也由kn上升到kn*n。
  - **组合模型阶段**：这一阶段主要是为了进一步提高特征交叉的维度，同时融合多个模型的优点。GBDT+LR是组合模型的代表方案，**GBDT自动进行特征筛选和组合得到新的离散特征向量输入LR模型**。GBDT+LR的组合方式开启了特征工程模型化的趋势，真正实现端到端训练。

### 2. 传统模型的特点总结

#### 2.1 协同过滤

- 根据用户的行为历史生成用户-物品共现矩阵，利用用户相似性和物品相似性进行推荐
- 简单直接、应用广泛
- 泛化能力差，处理稀疏矩阵的能力差，推荐结果的头部效应明显

#### 2.2 矩阵分解

- 将CF中的共现矩阵分解为用户矩阵和物品矩阵，利用用户隐向量和物品隐向量的内积进行排序并推荐
- 相较协同过滤，泛化能力有所加强，对稀疏矩阵的处理能力有所加强
- 除了用户历史行为数据，难以利用其他用户、物品特征及上下文特征

#### 2.3 逻辑回归

- 将推荐问题转化为类似点击率预估(CTR)的二分类问题，将用户、物品、上下文等多种不同的特征转换为特征向量，输入到逻辑回归模型得到CTR，再按照预估CTR进行排序并推荐
- 能融合多种不同种类的特征
- 不具备特征组合的能力，表达能力差

#### 2.4 FM

- 在逻辑回归的基础上，在模型中加入二阶特征交叉部分，为每一维特征训练得到相应特征隐向量，通过隐向量的内积运算得到交叉特征权重
- 相比逻辑回归，具备了二阶特征交叉能力，模型的表达能力加强
- 由于组合爆炸问题的限制，不易扩展到三阶特征交叉阶段

#### 2.5 FFM

- 在FM的基础上，加入特征域，使每个特征在于不同的特征域的特征交叉时采用不同的隐向量
- 相比FM，进一步提升了特征交叉的能力
- 训练开销较大

#### 2.6 GBDT+LR

- 利用GBDT进行自动的特征组合，将原始特征向量转换成离散型特征向量，并输入逻辑回归模型，进行最终的CTR预估
- 特征工程模型化，使模型具备了更高阶特征组合的能力
- 训练时间长

#### 2.7 LS-PLM

- 首先对样本进行“分片”，在每个“分片”的内部构建逻辑回归模型。将每个样本的“分片”概率与逻辑回归的得分进行加权平均，得到预估值
-  模型结构类似三层神经网络，具备较强的表达能力
- 相比深度模型较简单，有提升的空间